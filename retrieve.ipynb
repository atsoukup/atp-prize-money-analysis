{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_YEAR = 2009\n",
    "END_YEAR = datetime.datetime.now().year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_singles_overview_data(year, day):\n",
    "    url = f\"https://www.atptour.com/en/rankings/singles?rankRange=1-5000&rankDate={year}-12-{day}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    ranking_table = soup.find(\"table\", {\"class\": \"mega-table\"})\n",
    "\n",
    "    # return if there is no table meaning that the date is not a Monday\n",
    "    if ranking_table is None:\n",
    "        return False\n",
    "\n",
    "    rows = ranking_table.find_all(\"tr\")\n",
    "\n",
    "    # return if there is no data meaning that the date is not a Monday\n",
    "    if len(rows) == 1:\n",
    "        return False\n",
    "\n",
    "    singles = []\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all(\"td\")\n",
    "\n",
    "        ranking = int(cells[0].text.strip().replace(\"T\", \"\"))\n",
    "        country = cells[2].find(\"img\")[\"alt\"]\n",
    "        name = cells[3].text.strip()\n",
    "        player_id = cells[3].find(\"a\")[\"href\"].split(\"/\")[4]\n",
    "        link = \"https://www.atptour.com\" + cells[3].find(\"a\")[\"href\"]\n",
    "        age = cells[4].text.strip()\n",
    "        if age == \"\":\n",
    "            age = None\n",
    "        else:\n",
    "            age = int(age)\n",
    "        points = int(cells[5].text.strip().replace(\",\", \"\"))\n",
    "        tournaments_played = int(cells[7].text.strip())\n",
    "\n",
    "        singles.append({\n",
    "            \"ranking\": ranking,\n",
    "            \"country\": country,\n",
    "            \"name\": name,\n",
    "            \"player_id\": player_id,\n",
    "            \"link\": link,\n",
    "            \"age\": age,\n",
    "            \"points\": points,\n",
    "            \"tournaments_played\": tournaments_played\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(singles)\n",
    "    df.to_csv(f\"data/players/overview/singles/{str(year)}.gz\", index=False, compression=\"gzip\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_doubles_overview_data(year, day):\n",
    "    url = f\"https://www.atptour.com/en/rankings/doubles?rankRange=1-5000&rankDate={year}-12-{day}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    ranking_table = soup.find(\"table\", {\"class\": \"mega-table\"})\n",
    "    rows = ranking_table.find_all(\"tr\")\n",
    "\n",
    "    doubles = []\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all(\"td\")\n",
    "\n",
    "        ranking = int(cells[0].text.strip().replace(\"T\", \"\"))\n",
    "        country = cells[2].find(\"img\")[\"alt\"]\n",
    "        name = cells[3].text.strip()\n",
    "        player_id = cells[3].find(\"a\")[\"href\"].split(\"/\")[4]\n",
    "        link = \"https://www.atptour.com\" + cells[3].find(\"a\")[\"href\"]\n",
    "        age = cells[4].text.strip()\n",
    "        if age == \"\":\n",
    "            age = None\n",
    "        else:\n",
    "            age = int(age)\n",
    "        points = int(cells[5].text.strip().replace(\",\", \"\"))\n",
    "        tournaments_played = int(cells[7].text.strip())\n",
    "\n",
    "        doubles.append({\n",
    "            \"ranking\": ranking,\n",
    "            \"country\": country,\n",
    "            \"name\": name,\n",
    "            \"player_id\": player_id,\n",
    "            \"link\": link,\n",
    "            \"age\": age,\n",
    "            \"points\": points,\n",
    "            \"tournaments_played\": tournaments_played\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(doubles)\n",
    "    df.to_csv(f\"data/players/overview/doubles/{str(year)}.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcollect_doubles_overview_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mcollect_doubles_overview_data\u001b[0;34m(year, day)\u001b[0m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.atptour.com/en/rankings/doubles?rankRange=1-5000&rankDate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-12-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m----> 5\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ranking_table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmega-table\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      7\u001b[0m rows \u001b[38;5;241m=\u001b[39m ranking_table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTMLParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/html/parser.py:172\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    170\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_starttag(i)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m--> 172\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    174\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_comment(i)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/html/parser.py:420\u001b[0m, in \u001b[0;36mHTMLParser.parse_endtag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_data(rawdata[i:gtpos])\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cdata_mode()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:186\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_endtag\u001b[0;34m(self, name, check_already_closed)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle a closing tag, e.g. '</tag>'\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m:param name: A tag name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m   e.g. '<tag></tag>'.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m#print(\"END\", name)\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_already_closed \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_closed_empty_element:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# This is a redundant end tag for an empty-element tag.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# We've already called handle_endtag() for it, so just\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# check it off the list.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m#print(\"ALREADY CLOSED\", name)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_closed_empty_element\u001b[38;5;241m.\u001b[39mremove(name)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop through all years\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    # find the last Monday of the year\n",
    "    for day in range(31, 24, -1):\n",
    "        success = collect_singles_overview_data(year, day)\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        collect_doubles_overview_data(year, day)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_singles_activity_data(year):\n",
    "    singles = pd.read_csv(f\"data/players/overview/singles/{str(year)}.gz\")\n",
    "\n",
    "    players = []\n",
    "    for _, row in singles.iterrows():\n",
    "        activity_link = row[\"link\"].replace(\"overview\", \"player-activity\") + \"?year=\" + str(year) + \"&matchType=singles\"\n",
    "        response = requests.get(activity_link)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        activity_table = soup.find(\"div\", {\"data-filtered-module\": \"playerActivityTables\"})\n",
    "        if activity_table is None:\n",
    "            continue\n",
    "\n",
    "        activity_stats = soup.find(\"div\", {\"data-filtered-module\": \"playerActivityStats\"})\n",
    "        stats = activity_stats.find_all(\"div\", {\"class\": \"stat-value\"})\n",
    "        record = stats[1].text.strip()\n",
    "        total_wins = int(record.split(\"-\")[0])\n",
    "        total_losses = int(record.split(\"-\")[1])\n",
    "        total_prize_money = stats[3].text.strip().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "\n",
    "        tournaments = activity_table.find_all(\"div\", {\"class\": \"activity-tournament-table\"})\n",
    "\n",
    "        tournaments_played = []\n",
    "        for tourney in tournaments:\n",
    "            tournament_info = tourney.find(\"table\", {\"class\": \"tourney-results-wrapper\"})\n",
    "            tournament_type = tournament_info.find(\"img\")[\"alt\"].strip()\n",
    "            try:\n",
    "                tournament_name = tournament_info.find(\"a\", {\"class\": \"tourney-title\"}).text.strip()\n",
    "            except:\n",
    "                tournament_name = tournament_info.find(\"span\", {\"class\": \"tourney-title\"}).text.strip()\n",
    "\n",
    "            match_info = tourney.find(\"table\", {\"class\": \"mega-table\"})\n",
    "            match_rows = match_info.find_all(\"tr\")\n",
    "\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            for match in match_rows:\n",
    "                result = match.find_all(\"td\")[3].text.strip()\n",
    "                if result == \"W\":\n",
    "                    wins += 1\n",
    "                elif result == \"L\":\n",
    "                    losses += 1\n",
    "            \n",
    "            other_info = tourney.find(\"div\", {\"class\": \"activity-tournament-caption\"}).text.strip()\n",
    "            other_info_split = other_info.split(\", \")\n",
    "\n",
    "            points = 0\n",
    "            prize_money = \"\"\n",
    "            for info in other_info_split:\n",
    "                if \"Points\" in info:\n",
    "                    points = int(info.split(\" \")[-1])\n",
    "                elif \"Prize Money\" in info:\n",
    "                    prize_money = info.split(\" \")[-1].replace(\",\", \"\")\n",
    "\n",
    "            tournaments_played.append({\n",
    "                \"tournament_type\": tournament_type,\n",
    "                \"tournament_name\": tournament_name,\n",
    "                \"wins\": wins,\n",
    "                \"losses\": losses,\n",
    "                \"points\": points,\n",
    "                \"prize_money\": prize_money\n",
    "            })\n",
    "        \n",
    "        # include all other player info as well\n",
    "        players.append({\n",
    "            \"ranking\": row[\"ranking\"],\n",
    "            \"country\": row[\"country\"],\n",
    "            \"name\": row[\"name\"],\n",
    "            \"player_id\": row[\"player_id\"],\n",
    "            \"link\": row[\"link\"],\n",
    "            \"age\": row[\"age\"],\n",
    "            \"points\": row[\"points\"],\n",
    "            \"wins\": total_wins,\n",
    "            \"losses\": total_losses,\n",
    "            \"prize_money\": total_prize_money,\n",
    "            \"tournament_played\": row[\"tournaments_played\"],\n",
    "            \"tournaments\": tournaments_played\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(players)\n",
    "    df.to_csv(f\"data/players/activity/singles/{str(year)}.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_doubles_activity_data(year):\n",
    "    doubles = pd.read_csv(f\"data/players/overview/doubles/{str(year)}.gz\")\n",
    "\n",
    "    players = []\n",
    "    for _, row in doubles.iterrows():\n",
    "        activity_link = row[\"link\"].replace(\"overview\", \"player-activity\") + \"?year=\" + str(year) + \"&matchType=doubles\"\n",
    "        response = requests.get(activity_link)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        activity_table = soup.find(\"div\", {\"data-filtered-module\": \"playerActivityTables\"})\n",
    "        if activity_table is None:\n",
    "            continue\n",
    "\n",
    "        activity_stats = soup.find(\"div\", {\"data-filtered-module\": \"playerActivityStats\"})\n",
    "        stats = activity_stats.find_all(\"div\", {\"class\": \"stat-value\"})\n",
    "        record = stats[1].text.strip()\n",
    "        total_wins = int(record.split(\"-\")[0])\n",
    "        total_losses = int(record.split(\"-\")[1])\n",
    "        total_prize_money = stats[3].text.strip().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "\n",
    "        tournaments = activity_table.find_all(\"div\", {\"class\": \"activity-tournament-table\"})\n",
    "\n",
    "        tournaments_played = []\n",
    "        for tourney in tournaments:\n",
    "            tournament_info = tourney.find(\"table\", {\"class\": \"tourney-results-wrapper\"})\n",
    "            tournament_type = tournament_info.find(\"img\")[\"alt\"].strip()\n",
    "            try:\n",
    "                tournament_name = tournament_info.find(\"a\", {\"class\": \"tourney-title\"}).text.strip()\n",
    "            except:\n",
    "                tournament_name = tournament_info.find(\"span\", {\"class\": \"tourney-title\"}).text.strip()\n",
    "\n",
    "            match_info = tourney.find(\"table\", {\"class\": \"mega-table\"})\n",
    "            match_rows = match_info.find_all(\"tr\")\n",
    "\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            for match in match_rows:\n",
    "                result = match.find_all(\"td\")[3].text.strip()\n",
    "                if result == \"W\":\n",
    "                    wins += 1\n",
    "                elif result == \"L\":\n",
    "                    losses += 1\n",
    "\n",
    "            other_info = tourney.find(\"div\", {\"class\": \"activity-tournament-caption\"}).text.strip()\n",
    "            other_info_split = other_info.split(\", \")\n",
    "\n",
    "            points = 0\n",
    "            prize_money = \"\"\n",
    "            for info in other_info_split:\n",
    "                if \"Points\" in info:\n",
    "                    points = int(info.split(\" \")[-1])\n",
    "                elif \"Prize Money\" in info:\n",
    "                    prize_money = info.split(\" \")[-1].replace(\",\", \"\")\n",
    "\n",
    "            tournaments_played.append({\n",
    "                \"tournament_type\": tournament_type,\n",
    "                \"tournament_name\": tournament_name,\n",
    "                \"wins\": wins,\n",
    "                \"losses\": losses,\n",
    "                \"points\": points,\n",
    "                \"prize_money\": prize_money\n",
    "            })\n",
    "\n",
    "        # include all other player info as well\n",
    "        players.append({\n",
    "            \"ranking\": row[\"ranking\"],\n",
    "            \"country\": row[\"country\"],\n",
    "            \"name\": row[\"name\"],\n",
    "            \"player_id\": row[\"player_id\"],\n",
    "            \"link\": row[\"link\"],\n",
    "            \"age\": row[\"age\"],\n",
    "            \"points\": row[\"points\"],\n",
    "            \"wins\": total_wins,\n",
    "            \"losses\": total_losses,\n",
    "            \"prize_money\": total_prize_money,\n",
    "            \"tournament_played\": row[\"tournaments_played\"],\n",
    "            \"tournaments\": tournaments_played\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(players)\n",
    "    df.to_csv(f\"data/players/activity/doubles/{str(year)}.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all years\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    collect_singles_activity_data(year)\n",
    "    collect_doubles_activity_data(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
